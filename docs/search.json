[
  {
    "objectID": "step1_ocr.html",
    "href": "step1_ocr.html",
    "title": "Шаг 1: Извлечение текста из PDF",
    "section": "",
    "text": "Источник корпуса: 15 PDF-файлов рассказов Эдгара По.\nПапка: source_docs/\nИнструменты: pdftools для извлечения текста, magick для предобработки изображений (улучшение контраста, удаление перекоса).\nПример предобработки первой страницы (The Fall of the House of Usher): \n\n\n\nПолучено 15 файлов с сырым извлечённым текстом.\nПапка с результатами: raw_text/\nОбщий объём корпуса после очистки: ~293 тыс. символов.\nДемонстрация предобработки изображений показывает, как можно работать с полностью отсканированными источниками (если бы текстовый слой в PDF отсутствовал)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Главная",
    "section": "",
    "text": "1 Итоговый проект: Вариант 1\nКомплексный анализ корпуса с визуализацией\nАвтор: Дей Захар Дмитриевич\n\n\n\nЭдгар Аллан По\n\n\n\n“All that we see or seem is but a dream within a dream.”\n— Edgar Allan Poe\n\nКорпус состоит из 15 рассказов Эдгара Аллана По (английский язык):\nThe Fall of the House of Usher The Black Cat The Masque of the Red Death The Cask of Amontillado The Pit and the Pendulum The Purloined Letter The Facts in the Case of M. Valdemar The Premature Burial The Assignation Mesmeric Revelation The Imp of the Perverse The Island of the Fay Silence—A Fable The Thousand-and-Second Tale of Scheherazade Von Kempelen and His Discovery\n\n1.0.1 Что сделано:\n\nИзвлечение текста из PDF (pdftools + предобработка изображений magick)\nОчистка текста регулярными выражениями\nЛемматизация и частотный словарь (udpipe)\nПоиск коллокаций (quanteda) и визуализация (ggplot2, ggraph)\n\n\n\n1.0.2 Ключевые результаты\n\n\n\nТоп-30 лемм\n\n\n\n\n\nТоп-20 коллокаций\n\n\n\n\n\nСеть коллокаций (топ-30)\n\n\nИнтерпретация: Доминируют темы смерти, упадка, сверхъестественного. Коллокации прямо отсылают к названиям рассказов (“red death”, “house usher”, “black cat”).\n→ Используйте меню сверху для детального просмотра каждого шага."
  },
  {
    "objectID": "poe_analysis.html",
    "href": "poe_analysis.html",
    "title": "Шаги 2–4: Очистка текста, лемматизация, коллокации и визуализация",
    "section": "",
    "text": "1 Шаг 2: Очистка текста регулярными выражениями\nПосле извлечения текст содержал артефакты форматирования PDF (лишние переносы, тире, номера страниц). Очистка проводилась с помощью пакета stringr.\nЗадачи очистки: - Исправление типичных ошибок (например, “rn” → “m”, одинокая “l” → “I”) - Приведение к нижнему регистру - Удаление пунктуации, цифр и слишком коротких слов - Нормализация пробелов\nРезультат шага 1\n\nПолучено 15 файлов с сырым извлечённым текстом.\nПапка с результатами: raw_text/\nОбщий объём корпуса после очистки: ~293 тыс. символов.\nДемонстрация предобработки изображений показывает, как можно работать с полностью отсканированными источниками (если бы текстовый слой в PDF отсутствовал).\n\n\n\n2 Шаг 3: Лемматизация и лемматизированный частотный словарь\nЛемматизация и POS-тэггинг с помощьюudpipe. Учитывались только содержательные части речи (NOUN, ADJ, VERB), минимальная частота — 5.\n\n\nПоказать код\n# объединяем всё в один корпус\nclean_files &lt;- list.files(clean_dir, pattern = \"_clean\\\\.txt$\", full.names = TRUE)\n\ncorpus &lt;- \"\"   # сюда собираем весь текст\nfor (file in clean_files) {\n  text &lt;- readLines(file, encoding = \"UTF-8\")\n  corpus &lt;- paste(corpus, paste(text, collapse = \" \"))\n}\ncat(\"Корпус готов. Символов:\", nchar(corpus), \"\\n\\n\")\n\n# Загружаем модель udpipe\nmodel_path &lt;- \"english-ewt-ud-2.5-191206.udpipe\"\nud_model &lt;- udpipe_load_model(model_path)\n\n# лемматизация\nannotated &lt;- udpipe_annotate(ud_model, x = corpus)\nannotated &lt;- as.data.frame(annotated)\n\n# Частотный словарь лемм (существительные, прилагательные, глаголы)\ncat(\"Словарь\\n\")\nfreq_dict &lt;- annotated[annotated$upos %in% c(\"NOUN\", \"ADJ\", \"VERB\"), ]\nfreq_dict &lt;- table(freq_dict$lemma)\nfreq_dict &lt;- sort(freq_dict, decreasing = TRUE)\nfreq_dict &lt;- freq_dict[freq_dict &gt;= 5]   # частота слов &gt;= 5\n\n# Сохраняем словарь в файл\nwrite.csv(as.data.frame(freq_dict), file.path(results_dir, \"frequency_dictionary.csv\"), row.names = TRUE)\ncat(\"Частотный словарь сохранён\\n\")\n\n\n\n\n3 Топ-30 наиболее частотных лемм\n\n\nПоказать код\n# Берём топ лемм\ntop_n &lt;- min(30, length(freq_dict))\n\ntop30_names &lt;- names(freq_dict)[1:top_n]\ntop30_counts &lt;- as.numeric(freq_dict[1:top_n])\n\n# Создаём датафрейм\ntop30_df &lt;- data.frame(\n  lemma = top30_names,\n  count = top30_counts,\n  stringsAsFactors = FALSE\n)\n\n# График\nggplot(top30_df, aes(x = reorder(lemma, count), y = count)) +\n  geom_col(fill = \"darkred\", width = 0.7) +\n  coord_flip() +\n  labs(title = \"Топ-30 лемм в корпусе Эдгара Аллана По\",\n       x = \"Лемма\", y = \"Частота\") +\n  theme_minimal(base_size = 12)\n\nggsave(file.path(results_dir, \"top30_lemmas.png\"), width = 12, height = 9, dpi = 300)\n\n\n Интерпретация: доминируют слова, связанные со смертью (death), домом (house), временем (time), глазами (eye), сердцем (heart) — типичные мотивы готической прозы По. # Шаг 4: Коллокации и визуализация\n\n\nПоказать код\n# Коллокации\ntoks &lt;- tokens(corpus, remove_punct = TRUE, remove_symbols = TRUE, remove_numbers = TRUE)\n\ncolloc &lt;- textstat_collocations(toks, size = 2, min_count = 10)\ncolloc &lt;- colloc[order(colloc$count, decreasing = TRUE), ]\n\n# Берём топ-30\ntop_colloc &lt;- colloc[1:30, ]\n\nwrite.csv(top_colloc, file.path(results_dir, \"collocations.csv\"), row.names = FALSE)\n\ntop20_colloc &lt;- top_colloc[1:20, ]\nggplot(top20_colloc, aes(x = reorder(collocation, count), y = count)) +\n  geom_col(fill = \"darkblue\") +\n  coord_flip() +\n  labs(title = \"Топ-20 коллокаций в корпусе По\", x = \"Коллокация\", y = \"Частота\") +\n  theme_minimal()\nggsave(file.path(results_dir, \"top20_collocations_bar.png\"), width = 12, height = 8)\n\n\n Интерпретация: многие коллокации — прямые отсылки к названиям и ключевым образам рассказов: “red death”, “house usher”, “black cat”, “tell tale”, “fall house”.\n\n\n4 Сетевой график коллокаций\n\n\nПоказать код\n# Сетевой график коллокаций\nwords1 &lt;- character(nrow(top_colloc))\nwords2 &lt;- character(nrow(top_colloc))\nfor (i in 1:nrow(top_colloc)) {\n  parts &lt;- str_split(top_colloc$collocation[i], \" \")[[1]]\n  words1[i] &lt;- parts[1]\n  words2[i] &lt;- parts[2]\n}\ngraph_df &lt;- data.frame(word1 = words1, word2 = words2, weight = top_colloc$count)\n\ngraph &lt;- graph_from_data_frame(graph_df, directed = FALSE)\n\nggraph(graph, layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = weight, edge_width = weight), colour = \"lightgray\") +\n  geom_node_point(color = \"white\", size = 5) +\n  geom_node_text(aes(label = name), repel = TRUE, colour = \"white\") +\n  labs(title = \"Сеть топ-30 коллокаций\", colour = \"white\") +\n  theme_void()\nggsave(file.path(results_dir, \"collocations_network.png\"), width = 12, height = 10)\ncat(\"Готово\\n\")\n\n\n\n\n\nСеть коллокаций (топ-30)"
  },
  {
    "objectID": "step1_ocr.html#результат-шага-1",
    "href": "step1_ocr.html#результат-шага-1",
    "title": "Шаг 1: Извлечение текста из PDF",
    "section": "",
    "text": "Получено 15 файлов с сырым извлечённым текстом.\nПапка с результатами: raw_text/\nОбщий объём корпуса после очистки: ~293 тыс. символов.\nДемонстрация предобработки изображений показывает, как можно работать с полностью отсканированными источниками (если бы текстовый слой в PDF отсутствовал)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Выводы и информация о проекте",
    "section": "",
    "text": "1 Основные выводы анализа\nКорпус из 15 рассказов Эдгара Аллана По позволил выявить ключевые лексические особенности его прозы:\n\nДоминирующие темы: смерть (death), дом (house), время (time), глаз (eye), сердце (heart), страх (fear), тьма (dark). Эти леммы отражают готическую атмосферу упадка, безумия и сверхъестественного.\nЗначимые коллокации: “red death”, “house usher”, “black cat”, “tell tale”, “fall house” — прямые отсылки к названиям и центральным образам произведений.\nОбщая картина: лексика насыщена словами с негативной коннотацией, что создаёт ощущение неизбежности и ужаса — фирменный стиль По.\n\nАнализ подтверждает, что По мастерски использует повторяющиеся мотивы для построения напряжения.\n\n\n\n\nФинальная сеть коллокаций — визуализация ключевых связей\n\n\n\n\n\n2 Техническая реализация проекта\nВариант 1 выполнен полностью и с превышением требований задания:\n\n\n\n\n\n\n\nПункт задания\nВыполнение\n\n\n\n\n1. Извлечение текста (OCR с tesseract или из PDF)\nИзвлечение из 15 PDF (pdftools) + демонстрация предобработки изображений (magick)\n\n\n2. Очистка регулярными выражениями\nПолная очистка: исправление артефактов, нормализация, удаление шума\n\n\n3. Лемматизированный частотный словарь (udpipe)\nПостроен с фильтрацией по частям речи и частоте\n\n\n4. Коллокации и визуализация\nТри вида: барплот, таблица, сетевой график (ggraph)\n\n\n\nКорпус: &gt;10 документов (15 PDF, общественное достояние).\nОбщий объём: ~293 тыс. символов после очистки.\nИнструменты: R, pdftools, magick, stringr, udpipe, quanteda, ggplot2, ggraph.\nПроект полностью воспроизводим: достаточно запустить скрипты по порядку: 1. scripts/01.R 2. scripts/02.R 3. scripts/03.R\n\n\n3 Заключение\nРабота с текстами Эдгара По показала, насколько мощными могут быть простые методы цифрового анализа для выявления стилистических особенностей автора. Полученные результаты не только соответствуют литературным исследованиям творчества По, но и демонстрируют практическую ценность инструментов обработки естественного языка.\nСпасибо за интересный курс и возможность применить знания на классике мировой литературы!\n\n“The boundaries which divide Life from Death are at best shadowy and vague. Who shall say where the one ends, and where the other begins?”\n— Edgar Allan Poe, The Premature Burial\n\n\n\n\n\nТоп-30 лемм — лексический портрет корпуса"
  }
]